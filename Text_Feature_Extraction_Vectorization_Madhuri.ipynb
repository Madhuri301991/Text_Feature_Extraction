{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e2d7f",
   "metadata": {},
   "source": [
    "## Feature Extraction from Text using Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e883f",
   "metadata": {},
   "source": [
    "___\n",
    "# Feature Extraction from Text\n",
    " In this section we'll actually look at the text of each message and try to perform a classification based on content. We'll take advantage of some of scikit-learn's [feature extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) tools.\n",
    "\n",
    "## Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a2d7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1067b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('smsspamcollection.tsv',sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a75ebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#take raw text information and vectorize it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f300e1d",
   "metadata": {},
   "source": [
    "## Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47c7988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bc9c7",
   "metadata": {},
   "source": [
    "## Take a quick look at the *ham* and *spam* `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b50f1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40e53e",
   "metadata": {},
   "source": [
    "## Split the data into train & test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9889d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f005841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['message']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "882020eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bef6a",
   "metadata": {},
   "source": [
    "## Scikit-learn's CountVectorizer\n",
    "Text preprocessing, tokenizing and the ability to filter out stopwords are all included in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which builds a dictionary of features and transforms documents to feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c514016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e92849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts=count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e21e1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a18a40",
   "metadata": {},
   "source": [
    "This shows that our training set is comprised of 3733 documents, and 7082 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45a91e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ifidf can be used to give words that are important more weights\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "820cf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf=tfidf_transformer.fit_transform(X_train_counts)\n",
    "#pass countvectorizer to tfidf transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b97650bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278e4c0",
   "metadata": {},
   "source": [
    "Note: the `fit_transform()` method actually performs two operations: it fits an estimator to the data and then transforms our count-matrix to a tf-idf representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ce5d6",
   "metadata": {},
   "source": [
    "## Combine Steps with TfidVectorizer\n",
    "In the future, we can combine the CountVectorizer and TfidTransformer steps into one using [TfidVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cdda239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "#combines process of countvectorization and tfidftransformation\n",
    "tfidf_vectorizer=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dfe1da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 7082)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf=tfidf_vectorizer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e0248",
   "metadata": {},
   "source": [
    "## Train a Classifier\n",
    "Here we'll introduce an SVM classifier that's similar to SVC, called [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html). LinearSVC handles sparse input better, and scales well to large numbers of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e778150d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf=LinearSVC()\n",
    "clf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312a088",
   "metadata": {},
   "source": [
    "## Build a Pipeline\n",
    "Remember that only our training set has been vectorized into a full vocabulary. In order to perform an analysis on our test set we'll have to submit it to the same procedures. Fortunately scikit-learn offers a [**Pipeline**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class that behaves like a compound classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0acb49b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline can perform vectorization and classification \n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf=Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())]) #this line creates a pipeline\n",
    "text_clf.fit(X_train,y_train)#pass it raw training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f97b9d",
   "metadata": {},
   "source": [
    "## Test the classifier and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4badcd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#form a predication set\n",
    "predications=text_clf.predict(X_test)\n",
    "#X_test contains raw text messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "953703dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "#repost the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test,predications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "859a6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print a classification report\n",
    "print(classification_report(y_test,predications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db63b7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989668297988037"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the overall accuracy\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test,predications)\n",
    "#gives nearly 99 per accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0ec44",
   "metadata": {},
   "source": [
    "Using the text of the messages, our model performed exceedingly well; it correctly predicted spam **98.97%** of the time!<br>\n",
    "Now let's apply what we've learned to a text classification project involving positive and negative movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a001b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply on a new text message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5411e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"How are you doing today\"]) #pass the message as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f65d4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Congratulations! You've been selected as a winner. TEXT WON to 44255 congratulations free entry to contest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92d33210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    }
   ],
   "source": [
    "print(\"The End\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
